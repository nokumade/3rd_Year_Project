# 3rd_Year_Project

There is a plethora of situations when people cannot hear the voices on the video (e.g., hearing impairment, noisy environment) but still want to understand what people are saying on the screen of their smartphones or computers. One of the most popular video sources is YouTube, and it was introduced in 2007 and since then has refined its caption building algorithm. Today it can be considered one of the best subtitle generators, however for the purpose of efficacy, it doesn’t recognize the talking person, only recognizing his/her speech. So, our program is designed to fill that gap and build a more advanced caption builder using open-source libraries, such as OpenCV and face_recongnition.
Initially, we have been testing the software only on the Russian YouTube/VK Video show “Loud Question.” In each episode, there are four main hosts and one guest. During the show, they put on the headphones with loud music on and the guest reads the question and must explain the answer to the hosts while shouting or using their hands. We used a 15-minute sample from one of the episode and ran two tests, one with plain diarization, which used identified speakers by itself, and then with face recognition to get the real or most possible speaker based on the person in the frame while the speech. As a result, just diarization yielded worse results than with face recognition, however the latter required more time to compute.
